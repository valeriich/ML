{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 101 Pandas Exercises for Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. How to import pandas and check the version?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.4\n",
      "{'system': {'commit': None, 'python': '3.7.0.final.0', 'python-bits': 32, 'OS': 'Windows', 'OS-release': '8.1', 'machine': 'AMD64', 'processor': 'Intel64 Family 6 Model 76 Stepping 3, GenuineIntel', 'byteorder': 'little', 'LC_ALL': 'None', 'LANG': 'None', 'LOCALE': 'None.None'}, 'dependencies': {'pandas': '0.23.4', 'pytest': None, 'pip': '18.1', 'setuptools': '39.1.0', 'Cython': None, 'numpy': '1.15.3', 'scipy': '1.1.0', 'pyarrow': None, 'xarray': None, 'IPython': '7.1.1', 'sphinx': None, 'patsy': None, 'dateutil': '2.7.5', 'pytz': '2018.7', 'blosc': None, 'bottleneck': None, 'tables': None, 'numexpr': None, 'feather': None, 'matplotlib': '3.0.2', 'openpyxl': None, 'xlrd': None, 'xlwt': None, 'xlsxwriter': None, 'lxml': None, 'bs4': None, 'html5lib': None, 'sqlalchemy': None, 'pymysql': None, 'psycopg2': None, 'jinja2': '2.10', 's3fs': None, 'fastparquet': None, 'pandas_gbq': None, 'pandas_datareader': None}}\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  # optional\n",
    "import pandas as pd\n",
    "print(pd.__version__)\n",
    "print(pd.show_versions(as_json=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. How to create a series from a list, numpy array and dict?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "e    3\n",
      "d    4\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "import numpy as np\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "\n",
    "# Solution\n",
    "ser1 = pd.Series(mylist)\n",
    "ser2 = pd.Series(myarr)\n",
    "ser3 = pd.Series(mydict)\n",
    "print(ser3.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. How to convert the index of a series into a column of a dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the series **_ser_** into a dataframe with its index as another column on the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a    0\n",
      "b    1\n",
      "c    2\n",
      "e    3\n",
      "d    4\n",
      "dtype: int64\n",
      "  index  0\n",
      "0     a  0\n",
      "1     b  1\n",
      "2     c  2\n",
      "3     e  3\n",
      "4     d  4\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "mylist = list('abcedfghijklmnopqrstuvwxyz')\n",
    "myarr = np.arange(26)\n",
    "mydict = dict(zip(mylist, myarr))\n",
    "ser = pd.Series(mydict)\n",
    "\n",
    "# Solution\n",
    "df = ser.to_frame().reset_index()\n",
    "print(ser.head())\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. How to combine many series to form a dataframe?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine **_ser1_** and **_ser2_** to form a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   0  1\n",
      "0  a  0\n",
      "1  b  1\n",
      "2  c  2\n",
      "3  e  3\n",
      "4  d  4\n",
      "  col1  col2\n",
      "0    a     0\n",
      "1    b     1\n",
      "2    c     2\n",
      "3    e     3\n",
      "4    d     4\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "import numpy as np\n",
    "ser1 = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "ser2 = pd.Series(np.arange(26))\n",
    "\n",
    "# Solution 1\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "print(df.head())\n",
    "\n",
    "# Solution 2\n",
    "df = pd.DataFrame({'col1': ser1, 'col2': ser2})\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. How to assign name to the series’ index?\n",
    "Give a name to the series **_ser_** calling it ‘alphabets’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    a\n",
       "1    b\n",
       "2    c\n",
       "3    e\n",
       "4    d\n",
       "Name: alphabets, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(list('abcedfghijklmnopqrstuvwxyz'))\n",
    "\n",
    "# Solution\n",
    "ser.name = 'alphabets'\n",
    "ser.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. How to get the items of series A not present in series B?\n",
    "From **_ser1_** remove items present in **_ser2_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "# Solution\n",
    "ser1[~ser1.isin(ser2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. How to get the items not common to both series A and series B?\n",
    "Get all items of **_ser1_** and **_ser2_** not common to both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "3    4\n",
       "4    5\n",
       "5    6\n",
       "6    7\n",
       "7    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series([1, 2, 3, 4, 5])\n",
    "ser2 = pd.Series([4, 5, 6, 7, 8])\n",
    "\n",
    "# Solution\n",
    "ser_u = pd.Series(np.union1d(ser1, ser2))  # union\n",
    "ser_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_i = pd.Series(np.intersect1d(ser1, ser2))  # intersect\n",
    "ser_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    2\n",
       "2    3\n",
       "5    6\n",
       "6    7\n",
       "7    8\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_u[~ser_u.isin(ser_i)] # delete common items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. How to get the minimum, 25th percentile, median, 75th, and max of a numeric series?\n",
    "Compute the minimum, 25th percentile, median, 75th, and maximum of **_ser_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.25117263,  7.70986507, 10.92259345, 13.36360403, 18.0949083 ])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "state = np.random.RandomState(100)\n",
    "ser = pd.Series(state.normal(10, 5, 25))\n",
    "\n",
    "# Solution\n",
    "np.percentile(ser, q=[0, 25, 50, 75, 100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. How to get frequency counts of unique items of a series?\n",
    "Calculte the frequency counts of each unique value **_ser_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    5\n",
       "d    5\n",
       "h    4\n",
       "f    4\n",
       "b    3\n",
       "c    3\n",
       "e    3\n",
       "a    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.take(list('abcdefgh'), np.random.randint(8, size=30)))\n",
    "\n",
    "# Solution\n",
    "ser.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. How to keep only top 2 most frequent values as it is and replace everything else as ‘Other’?\n",
    "From **_ser_**, keep the top 2 most frequent items as it is and replace everything else as ‘Other’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     1\n",
      "1     3\n",
      "2     2\n",
      "3     4\n",
      "4     3\n",
      "5     4\n",
      "6     4\n",
      "7     4\n",
      "8     1\n",
      "9     4\n",
      "10    4\n",
      "11    4\n",
      "dtype: int32\n",
      "Top 2 Freq: 4    7\n",
      "3    2\n",
      "1    2\n",
      "2    1\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     Other\n",
       "1         3\n",
       "2     Other\n",
       "3         4\n",
       "4         3\n",
       "5         4\n",
       "6         4\n",
       "7         4\n",
       "8     Other\n",
       "9         4\n",
       "10        4\n",
       "11        4\n",
       "dtype: object"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "np.random.RandomState(100)\n",
    "ser = pd.Series(np.random.randint(1, 5, [12]))\n",
    "print(ser)\n",
    "\n",
    "# Solution\n",
    "print(\"Top 2 Freq:\", ser.value_counts())\n",
    "ser[~ser.isin(ser.value_counts().index[:2])] = 'Other'\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. How to bin a numeric series to 10 groups of equal size?\n",
    "Bin the series **_ser_** into 10 equal deciles and replace the values with the bin name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.507193\n",
      "1    0.643937\n",
      "2    0.995664\n",
      "3    0.136835\n",
      "4    0.041169\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     4th\n",
       "1     6th\n",
       "2    10th\n",
       "3     1st\n",
       "4     1st\n",
       "dtype: category\n",
       "Categories (10, object): [1st < 2nd < 3rd < 4th ... 7th < 8th < 9th < 10th]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.random(20))\n",
    "print(ser.head())\n",
    "\n",
    "# Solution\n",
    "pd.qcut(ser, q=[0, .10, .20, .3, .4, .5, .6, .7, .8, .9, 1], \n",
    "        labels=['1st', '2nd', '3rd', '4th', '5th', '6th', '7th', '8th', '9th', '10th']).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. How to convert a numpy array to a dataframe of given shape?\n",
    "Reshape the series **_ser_** into a dataframe with 7 rows and 5 columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     3\n",
      "1     7\n",
      "2     7\n",
      "3     1\n",
      "4     6\n",
      "5     7\n",
      "6     9\n",
      "7     9\n",
      "8     5\n",
      "9     5\n",
      "10    1\n",
      "11    2\n",
      "12    4\n",
      "13    6\n",
      "14    4\n",
      "15    1\n",
      "16    7\n",
      "17    2\n",
      "18    8\n",
      "19    4\n",
      "20    2\n",
      "21    9\n",
      "22    2\n",
      "23    8\n",
      "24    9\n",
      "25    4\n",
      "26    4\n",
      "27    1\n",
      "28    5\n",
      "29    4\n",
      "30    3\n",
      "31    7\n",
      "32    5\n",
      "33    8\n",
      "34    6\n",
      "dtype: int32\n",
      "   0  1  2  3  4\n",
      "0  3  7  7  1  6\n",
      "1  7  9  9  5  5\n",
      "2  1  2  4  6  4\n",
      "3  1  7  2  8  4\n",
      "4  2  9  2  8  9\n",
      "5  4  4  1  5  4\n",
      "6  3  7  5  8  6\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.randint(1, 10, 35))\n",
    "print(ser)\n",
    "\n",
    "# Solution\n",
    "df = pd.DataFrame(ser.values.reshape(7,5))\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. How to find the positions of numbers that are multiples of 3 from a series?\n",
    "Find the positions of numbers that are multiples of 3 from **_ser_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    5\n",
      "1    1\n",
      "2    4\n",
      "3    6\n",
      "4    3\n",
      "5    6\n",
      "6    1\n",
      "dtype: int32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3],\n",
       "       [4],\n",
       "       [5]], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.random.randint(1, 10, 7))\n",
    "ser\n",
    "\n",
    "# Solution\n",
    "print(ser)\n",
    "np.argwhere(ser % 3 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. How to extract items at given positions from a series\n",
    "From **_ser_**, extract the items at positions in list **_pos_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     a\n",
       "4     e\n",
       "8     i\n",
       "14    o\n",
       "20    u\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(list('abcdefghijklmnopqrstuvwxyz'))\n",
    "pos = [0, 4, 8, 14, 20]\n",
    "\n",
    "# Solution\n",
    "ser.take(pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. How to stack two series vertically and horizontally ?\n",
    "Stack **_ser1_** and **_ser2_** vertically and horizontally (to form a dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    1\n",
      "2    2\n",
      "3    3\n",
      "4    4\n",
      "0    a\n",
      "1    b\n",
      "2    c\n",
      "3    d\n",
      "4    e\n",
      "dtype: object\n",
      "   0  1\n",
      "0  0  a\n",
      "1  1  b\n",
      "2  2  c\n",
      "3  3  d\n",
      "4  4  e\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series(range(5))\n",
    "ser2 = pd.Series(list('abcde'))\n",
    "\n",
    "# Output\n",
    "# Vertical\n",
    "print(ser1.append(ser2))\n",
    "\n",
    "\n",
    "# Horizontal\n",
    "df = pd.concat([ser1, ser2], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. How to get the positions of items of series A in another series B?\n",
    "Get the positions of items of **_ser2_** in **_ser1_** as a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5, 4, 0, 8]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser1 = pd.Series([10, 9, 6, 5, 3, 1, 12, 8, 13])\n",
    "ser2 = pd.Series([1, 3, 10, 13])\n",
    "\n",
    "# Solution 1\n",
    "[np.where(i == ser1)[0].tolist()[0] for i in ser2]\n",
    "\n",
    "# Solution 2\n",
    "[pd.Index(ser1).get_loc(i) for i in ser2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. How to compute the mean squared error on a truth and predicted series?\n",
    "Compute the mean squared error of **_truth_** and **_pred_** series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   truth      pred\n",
      "0      0  0.462559\n",
      "1      1  1.656042\n",
      "2      2  2.374960\n",
      "3      3  3.485993\n",
      "4      4  4.008992\n",
      "5      5  5.364015\n",
      "6      6  6.398672\n",
      "7      7  7.745345\n",
      "8      8  8.341968\n",
      "9      9  9.909613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.2812540625484167"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "truth = pd.Series(range(10))\n",
    "pred = pd.Series(range(10)) + np.random.random(10)\n",
    "df = pd.concat([truth, pred], axis=1)\n",
    "df.columns=['truth', 'pred']\n",
    "print(df)\n",
    "\n",
    "# Solution\n",
    "np.mean((truth-pred)**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 18. How to convert the first character of each element in a series to uppercase?\n",
    "Change the first character of each word to upper case in each word of **_ser_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     How\n",
       "1      To\n",
       "2    Kick\n",
       "3    Ass?\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "# Solution 1\n",
    "ser.map(lambda x: x.title())\n",
    "\n",
    "# Solution 2\n",
    "ser.map(lambda x: x[0].upper() + x[1:])\n",
    "\n",
    "# Solution 3\n",
    "pd.Series([i.title() for i in ser])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 19. How to calculate the number of characters in each word in a series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3\n",
       "1    2\n",
       "2    4\n",
       "3    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['how', 'to', 'kick', 'ass?'])\n",
    "\n",
    "# Solution\n",
    "ser.map(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 20. How to compute difference of differences between consequtive numbers of a series?\n",
    "Difference of differences between the consequtive numbers of **_ser_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nan, 2.0, 3.0, 4.0, 5.0, 6.0, 6.0, 8.0]\n",
      "[nan, nan, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0]\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series([1, 3, 6, 10, 15, 21, 27, 35])\n",
    "\n",
    "# Solution\n",
    "print(ser.diff().tolist())\n",
    "print(ser.diff().diff().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 21. How to convert a series of date-strings to a timeseries?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-01 00:00:00\n",
       "1   2011-02-02 00:00:00\n",
       "2   2012-03-03 00:00:00\n",
       "3   2013-04-04 00:00:00\n",
       "4   2014-05-05 00:00:00\n",
       "5   2015-06-06 12:20:00\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "ser.map(lambda x: parse(x))\n",
    "\n",
    "# Solution 2\n",
    "pd.to_datetime(ser)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 22. How to get the day of month, week number, day of year and day of week from a series of date strings?\n",
    "Get the day of month, week number, day of year and day of week from **_ser_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date:  [1, 2, 3, 4, 5, 6]\n",
      "Week number:  [53, 5, 9, 14, 19, 23]\n",
      "Day number of year:  [1, 33, 63, 94, 125, 157]\n",
      "Day of week:  ['Friday', 'Wednesday', 'Saturday', 'Thursday', 'Monday', 'Saturday']\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['01 Jan 2010', '02-02-2011', '20120303', '2013/04/04', '2014-05-05', '2015-06-06T12:20'])\n",
    "\n",
    "# Solution\n",
    "from dateutil.parser import parse\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# day of month\n",
    "print(\"Date: \", ser_ts.dt.day.tolist())\n",
    "\n",
    "# week number\n",
    "print(\"Week number: \", ser_ts.dt.weekofyear.tolist())\n",
    "\n",
    "# day of year\n",
    "print(\"Day number of year: \", ser_ts.dt.dayofyear.tolist())\n",
    "\n",
    "# day of week\n",
    "print(\"Day of week: \", ser_ts.dt.weekday_name.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 23. How to convert year-month string to dates corresponding to the 4th day of the month?\n",
    "Change **_ser_** to dates that start with 4th of the respective months."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2010-01-04\n",
       "1   2011-02-04\n",
       "2   2012-03-04\n",
       "dtype: datetime64[ns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['Jan 2010', 'Feb 2011', 'Mar 2012'])\n",
    "\n",
    "# Solution 1\n",
    "from dateutil.parser import parse\n",
    "# Parse the date\n",
    "ser_ts = ser.map(lambda x: parse(x))\n",
    "\n",
    "# Construct date string with date as 4\n",
    "ser_datestr = ser_ts.dt.year.astype('str') + '-' + ser_ts.dt.month.astype('str') + '-' + '04'\n",
    "\n",
    "# Format it.\n",
    "[parse(i).strftime('%Y-%m-%d') for i in ser_datestr]\n",
    "\n",
    "# Solution 2\n",
    "ser.map(lambda x: parse('04 ' + x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 24. How to filter words that contain atleast 2 vowels from a series?\n",
    "From **_ser_**, extract words that contain atleast 2 vowels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     Apple\n",
       "1    Orange\n",
       "4     Money\n",
       "dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(['Apple', 'Orange', 'Plan', 'Python', 'Money'])\n",
    "\n",
    "# Solution\n",
    "from collections import Counter\n",
    "mask = ser.map(lambda x: sum([Counter(x.lower()).get(i, 0) for i in list('aeiou')]) >= 2)\n",
    "ser[mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25. How to filter valid emails from a series?\n",
    "Extract the valid emails from the series **_emails_**. The regex pattern for valid emails is provided as reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    rameses@egypt.com\n",
      "2            matt@t.co\n",
      "3    narendra@modi.com\n",
      "dtype: object\n",
      "0                     []\n",
      "1    [rameses@egypt.com]\n",
      "2            [matt@t.co]\n",
      "3    [narendra@modi.com]\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['rameses@egypt.com', 'matt@t.co', 'narendra@modi.com']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "emails = pd.Series(['buying books at amazom.com', 'rameses@egypt.com', 'matt@t.co', 'narendra@modi.com'])\n",
    "\n",
    "# Solution 1 (as series of strings)\n",
    "import re\n",
    "pattern ='[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,4}'\n",
    "mask = emails.map(lambda x: bool(re.match(pattern, x)))\n",
    "print(emails[mask])\n",
    "\n",
    "\n",
    "# Solution 2 (as series of list)\n",
    "print(emails.str.findall(pattern, flags=re.IGNORECASE))\n",
    "\n",
    "# Solution 3 (as list)\n",
    "[x[0] for x in [re.findall(pattern, email) for email in emails] if len(x) > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 26. How to get the mean of a series grouped by another series?\n",
    "Compute the mean of **_weights_** of each **_fruit_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apple     4.0\n",
       "banana    5.5\n",
       "carrot    6.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "fruit = pd.Series(np.random.choice(['apple', 'banana', 'carrot'], 10))\n",
    "weights = pd.Series(np.linspace(1, 10, 10))\n",
    "\n",
    "# Solution\n",
    "weights.groupby(fruit).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 27. How to compute the euclidean distance between two series?\n",
    "Compute the [euclidean distance](https://en.wikipedia.org/wiki/Euclidean_distance) between series (points) **_p_** and **_q_**, without using a packaged formula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.16590212458495"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "p = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
    "q = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
    "\n",
    "# Solution \n",
    "sum((p - q)**2)**.5\n",
    "\n",
    "# Solution (using func)\n",
    "np.linalg.norm(p-q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 28. How to find all the local maxima (or peaks) in a numeric series?\n",
    "Get the positions of peaks (values surrounded by smaller values on both sides) in **_ser_**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8 -7  1  5  1 -8  5 -4]\n",
      "[ 1 -1  1  1  1 -1  1 -1]\n",
      "[-2  2  0  0 -2  2 -2]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 5, 7], dtype=int32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series([2, 10, 3, 4, 9, 10, 2, 7, 3])\n",
    "\n",
    "# Solution\n",
    "dd = np.diff(np.sign(np.diff(ser)))\n",
    "print(np.diff(ser))\n",
    "print(np.sign(np.diff(ser)))\n",
    "print(dd)\n",
    "peak_locs = np.where(dd == -2)[0] + 1\n",
    "peak_locs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29. How to replace missing spaces in a string with the least frequent character?\n",
    "Replace the spaces in ***my_str*** with the least frequent character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "d    4\n",
      "b    3\n",
      "e    3\n",
      "     3\n",
      "a    2\n",
      "g    1\n",
      "c    1\n",
      "dtype: int64\n",
      "c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'dbccdebcabedcgade'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "my_str = 'dbc deb abed gade'\n",
    "\n",
    "# Solution\n",
    "ser = pd.Series(list('dbc deb abed gade'))\n",
    "freq = ser.value_counts()\n",
    "print(freq)\n",
    "least_freq = freq.dropna().index[-1]\n",
    "print(least_freq)\n",
    "\"\".join(ser.replace(' ', least_freq))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30. How to create a TimeSeries starting ‘2000-01-01’ and 10 weekends (saturdays) after that having random numbers as values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000-01-01    1\n",
       "2000-01-08    5\n",
       "2000-01-15    6\n",
       "2000-01-22    7\n",
       "2000-01-29    6\n",
       "2000-02-05    3\n",
       "2000-02-12    1\n",
       "2000-02-19    9\n",
       "2000-02-26    7\n",
       "2000-03-04    3\n",
       "Freq: W-SAT, dtype: int32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "ser = pd.Series(np.random.randint(1,10,10), pd.date_range('2000-01-01', periods=10, freq='W-SAT'))\n",
    "ser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 31. How to fill an intermittent time series so all missing dates show up with values of previous non-missing date?\n",
    "***ser*** has missing dates and values. Make all missing dates appear and fill up with value from previous date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-01-01     1.0\n",
      "2000-01-03    10.0\n",
      "2000-01-06     3.0\n",
      "2000-01-08     NaN\n",
      "dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2000-01-01     1.0\n",
       "2000-01-02    10.0\n",
       "2000-01-03    10.0\n",
       "2000-01-04     3.0\n",
       "2000-01-05     3.0\n",
       "2000-01-06     3.0\n",
       "2000-01-07     3.0\n",
       "2000-01-08     3.0\n",
       "Freq: D, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series([1,10,3, np.nan], index=pd.to_datetime(['2000-01-01', '2000-01-03', '2000-01-06', '2000-01-08']))\n",
    "print(ser)\n",
    "\n",
    "# Solution\n",
    "ser.resample('D').ffill()  # fill with previous value\n",
    "\n",
    "# Alternatives\n",
    "ser.resample('D').bfill()  # fill with next value\n",
    "ser.resample('D').bfill().ffill()  # fill next else prev value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 32. How to compute the autocorrelations of a numeric series?\n",
    "Compute autocorrelations for the first 10 lags of ***ser***. Find out which lag has the largest correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     16.212849\n",
      "1     12.359428\n",
      "2      3.106418\n",
      "3      5.975342\n",
      "4     14.385312\n",
      "5      2.304043\n",
      "6     -1.432386\n",
      "7      3.517264\n",
      "8      6.574908\n",
      "9     -5.144513\n",
      "10    11.366448\n",
      "11     5.417499\n",
      "12     8.826876\n",
      "13     2.297674\n",
      "14    21.065121\n",
      "15    22.204620\n",
      "16    21.856173\n",
      "17    24.355133\n",
      "18    22.772467\n",
      "19    13.582535\n",
      "dtype: float64\n",
      "[0.54, 0.43, 0.4, 0.36, -0.27, -0.19, -0.15, -0.48, -0.73, -0.22]\n",
      "Lag having highest correlation:  9\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "ser = pd.Series(np.arange(20) + np.random.normal(1, 10, 20))\n",
    "print(ser)\n",
    "\n",
    "# Solution\n",
    "autocorrelations = [ser.autocorr(i).round(2) for i in range(11)]\n",
    "print(autocorrelations[1:])\n",
    "print('Lag having highest correlation: ', np.argmax(np.abs(autocorrelations[1:]))+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 33. How to import only every nth row from a csv file to create a dataframe?\n",
    "Import every 50th row of [BostonHousing](https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv) dataset as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  zn  indus chas    nox     rm   age     dis rad  tax ptratio  \\\n",
      "0  0.21977   0   6.91    0  0.448  5.602    62  6.0877   3  233    17.9   \n",
      "1   0.0686   0   2.89    0  0.445  7.416  62.5  3.4952   2  276      18   \n",
      "2  2.73397   0  19.58    0  0.871  5.597  94.9  1.5257   5  403    14.7   \n",
      "3   0.0315  95   1.47    0  0.403  6.975  15.3  7.6534   3  402      17   \n",
      "4  0.19073  22   5.86    0  0.431  6.718  17.5  7.8265   7  330    19.1   \n",
      "\n",
      "        b  lstat  medv  \n",
      "0   396.9   16.2  19.4  \n",
      "1   396.9   6.19  33.2  \n",
      "2  351.85  21.45  15.4  \n",
      "3   396.9   4.56  34.9  \n",
      "4  393.74   6.56  26.2  \n"
     ]
    }
   ],
   "source": [
    "# Solution 1: Use chunks and for-loop\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.DataFrame()\n",
    "for chunk in df:\n",
    "    df2 = df2.append(chunk.iloc[0,:])\n",
    "\n",
    "\n",
    "# Solution 2: Use chunks and list comprehension\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', chunksize=50)\n",
    "df2 = pd.concat([chunk.iloc[0] for chunk in df], axis=1)\n",
    "df2 = df2.transpose()\n",
    "\n",
    "# Solution 3: Use csv reader\n",
    "import csv          \n",
    "with open('BostonHousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i%50 == 0:\n",
    "            out.append(row)\n",
    "\n",
    "df2 = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 34. How to change column values when importing csv to a dataframe?\n",
    "Import the boston housing dataset, but while importing change the ***'medv'*** (median house value) column so that values < 25 becomes ‘Low’ and > 25 becomes ‘High’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  zn indus chas    nox     rm   age     dis rad  tax ptratio  \\\n",
      "0  0.00632  18  2.31    0  0.538  6.575  65.2    4.09   1  296    15.3   \n",
      "1  0.02731   0  7.07    0  0.469  6.421  78.9  4.9671   2  242    17.8   \n",
      "2  0.02729   0  7.07    0  0.469  7.185  61.1  4.9671   2  242    17.8   \n",
      "3  0.03237   0  2.18    0  0.458  6.998  45.8  6.0622   3  222    18.7   \n",
      "4  0.06905   0  2.18    0  0.458  7.147  54.2  6.0622   3  222    18.7   \n",
      "\n",
      "        b lstat  medv  \n",
      "0   396.9  4.98   Low  \n",
      "1   396.9  9.14   Low  \n",
      "2  392.83  4.03  High  \n",
      "3  394.63  2.94  High  \n",
      "4   396.9  5.33  High  \n"
     ]
    }
   ],
   "source": [
    "# Solution 1: Using converter parameter\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', \n",
    "                 converters={'medv': lambda x: 'High' if float(x) > 25 else 'Low'})\n",
    "\n",
    "\n",
    "# Solution 2: Using csv reader\n",
    "import csv\n",
    "with open('BostonHousing.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    out = []\n",
    "    for i, row in enumerate(reader):\n",
    "        if i > 0:\n",
    "            row[13] = 'High' if float(row[13]) > 25 else 'Low'\n",
    "        out.append(row)\n",
    "\n",
    "df = pd.DataFrame(out[1:], columns=out[0])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 35. How to create a dataframe with rows as strides from a given series?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 2,  3,  4,  5],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 6,  7,  8,  9],\n",
       "       [ 8,  9, 10, 11],\n",
       "       [10, 11, 12, 13]], dtype=int64)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = pd.Series(range(15))\n",
    "\n",
    "def gen_strides(a, stride_len=5, window_len=5):\n",
    "    n_strides = ((a.size-window_len)//stride_len) + 1\n",
    "    return np.array([a[s:(s+window_len)] for s in np.arange(0, a.size, stride_len)[:n_strides]])\n",
    "\n",
    "gen_strides(L, stride_len=2, window_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 36. How to import only specified columns from a csv file?\n",
    "Import ***‘crim’*** and ***‘medv’*** columns of the BostonHousing dataset as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      crim  medv\n",
      "0  0.00632  24.0\n",
      "1  0.02731  21.6\n",
      "2  0.02729  34.7\n",
      "3  0.03237  33.4\n",
      "4  0.06905  36.2\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/BostonHousing.csv', usecols=['crim', 'medv'])\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 37. How to get the nrows, ncolumns, datatype, summary stats of each column of a dataframe? Also get the array and list equivalent.\n",
    "Get the number of rows, columns, datatype and summary statistics of each column of the [Cars93](https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv) dataset. Also get the numpy array and list equivalent of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93, 27)\n",
      "Manufacturer           object\n",
      "Model                  object\n",
      "Type                   object\n",
      "Min.Price             float64\n",
      "Price                 float64\n",
      "Max.Price             float64\n",
      "MPG.city              float64\n",
      "MPG.highway           float64\n",
      "AirBags                object\n",
      "DriveTrain             object\n",
      "Cylinders              object\n",
      "EngineSize            float64\n",
      "Horsepower            float64\n",
      "RPM                   float64\n",
      "Rev.per.mile          float64\n",
      "Man.trans.avail        object\n",
      "Fuel.tank.capacity    float64\n",
      "Passengers            float64\n",
      "Length                float64\n",
      "Wheelbase             float64\n",
      "Width                 float64\n",
      "Turn.circle           float64\n",
      "Rear.seat.room        float64\n",
      "Luggage.room          float64\n",
      "Weight                float64\n",
      "Origin                 object\n",
      "Make                   object\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 93 entries, 0 to 92\n",
      "Data columns (total 27 columns):\n",
      "Manufacturer          89 non-null object\n",
      "Model                 92 non-null object\n",
      "Type                  90 non-null object\n",
      "Min.Price             86 non-null float64\n",
      "Price                 91 non-null float64\n",
      "Max.Price             88 non-null float64\n",
      "MPG.city              84 non-null float64\n",
      "MPG.highway           91 non-null float64\n",
      "AirBags               87 non-null object\n",
      "DriveTrain            86 non-null object\n",
      "Cylinders             88 non-null object\n",
      "EngineSize            91 non-null float64\n",
      "Horsepower            86 non-null float64\n",
      "RPM                   90 non-null float64\n",
      "Rev.per.mile          87 non-null float64\n",
      "Man.trans.avail       88 non-null object\n",
      "Fuel.tank.capacity    85 non-null float64\n",
      "Passengers            91 non-null float64\n",
      "Length                89 non-null float64\n",
      "Wheelbase             92 non-null float64\n",
      "Width                 87 non-null float64\n",
      "Turn.circle           88 non-null float64\n",
      "Rear.seat.room        89 non-null float64\n",
      "Luggage.room          74 non-null float64\n",
      "Weight                86 non-null float64\n",
      "Origin                88 non-null object\n",
      "Make                  90 non-null object\n",
      "dtypes: float64(18), object(9)\n",
      "memory usage: 16.4+ KB\n",
      "None\n",
      "float64    18\n",
      "object      9\n",
      "dtype: int64\n",
      "float64    18\n",
      "object      9\n",
      "dtype: int64\n",
      "       Min.Price      Price  Max.Price   MPG.city  MPG.highway  EngineSize  \\\n",
      "count  86.000000  91.000000  88.000000  84.000000    91.000000   91.000000   \n",
      "mean   17.118605  19.616484  21.459091  22.404762    29.065934    2.658242   \n",
      "std     8.828290   9.724280  10.696563   5.841520     5.370293    1.045845   \n",
      "min     6.700000   7.400000   7.900000  15.000000    20.000000    1.000000   \n",
      "25%    10.825000  12.350000  14.575000  18.000000    26.000000    1.800000   \n",
      "50%    14.600000  17.700000  19.150000  21.000000    28.000000    2.300000   \n",
      "75%    20.250000  23.500000  24.825000  25.000000    31.000000    3.250000   \n",
      "max    45.400000  61.900000  80.000000  46.000000    50.000000    5.700000   \n",
      "\n",
      "       Horsepower          RPM  Rev.per.mile  Fuel.tank.capacity  Passengers  \\\n",
      "count   86.000000    90.000000     87.000000           85.000000   91.000000   \n",
      "mean   144.000000  5276.666667   2355.000000           16.683529    5.076923   \n",
      "std     53.455204   605.554811    486.916616            3.375748    1.045953   \n",
      "min     55.000000  3800.000000   1320.000000            9.200000    2.000000   \n",
      "25%    100.750000  4800.000000   2017.500000           14.500000    4.000000   \n",
      "50%    140.000000  5200.000000   2360.000000           16.500000    5.000000   \n",
      "75%    170.000000  5787.500000   2565.000000           19.000000    6.000000   \n",
      "max    300.000000  6500.000000   3755.000000           27.000000    8.000000   \n",
      "\n",
      "           Length   Wheelbase      Width  Turn.circle  Rear.seat.room  \\\n",
      "count   89.000000   92.000000  87.000000    88.000000       89.000000   \n",
      "mean   182.865169  103.956522  69.448276    38.954545       27.853933   \n",
      "std     14.792651    6.856317   3.778023     3.304157        3.018129   \n",
      "min    141.000000   90.000000  60.000000    32.000000       19.000000   \n",
      "25%    174.000000   98.000000  67.000000    36.000000       26.000000   \n",
      "50%    181.000000  103.000000  69.000000    39.000000       27.500000   \n",
      "75%    192.000000  110.000000  72.000000    42.000000       30.000000   \n",
      "max    219.000000  119.000000  78.000000    45.000000       36.000000   \n",
      "\n",
      "       Luggage.room       Weight  \n",
      "count     74.000000    86.000000  \n",
      "mean      13.986486  3104.593023  \n",
      "std        3.120824   600.129993  \n",
      "min        6.000000  1695.000000  \n",
      "25%       12.000000  2647.500000  \n",
      "50%       14.000000  3085.000000  \n",
      "75%       16.000000  3567.500000  \n",
      "max       22.000000  4105.000000  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "#  number of rows and columns\n",
    "print(df.shape)\n",
    "\n",
    "# datatypes\n",
    "print(df.dtypes)\n",
    "print(df.info())\n",
    "\n",
    "# how many columns under each dtype\n",
    "print(df.get_dtype_counts())\n",
    "print(df.dtypes.value_counts())\n",
    "\n",
    "# summary statistics\n",
    "df_stats = df.describe()\n",
    "print(df_stats)\n",
    "\n",
    "# numpy array \n",
    "df_arr = df.values\n",
    "\n",
    "# list\n",
    "df_list = df.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 38. How to extract the row and column number of a particular cell with given criterion?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Manufacturer Model     Type\n",
      "58  Mercedes-Benz  300E  Midsize\n",
      "[58] [4]\n",
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\user\\pycharmprojects\\ml\\venv\\lib\\site-packages\\ipykernel_launcher.py:18: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "61.9"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "# Get Manufacturer with highest price\n",
    "print(df.loc[df.Price == np.max(df.Price), ['Manufacturer', 'Model', 'Type']])\n",
    "\n",
    "# Get Row and Column number\n",
    "row, col = np.where(df.values == np.max(df.Price))\n",
    "print(row, col)\n",
    "print(type(row))\n",
    "\n",
    "# Get the value\n",
    "df.iat[row[0], col[0]]\n",
    "df.iloc[row[0], col[0]]\n",
    "\n",
    "# Alternates\n",
    "df.at[row[0], 'Price']\n",
    "df.get_value(row[0], 'Price')\n",
    "\n",
    "# The difference between `iat` - `iloc` vs `at` - `loc` is:\n",
    "# `iat` snd `iloc` accepts row and column numbers. \n",
    "# Whereas `at` and `loc` accepts index and column names."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 39. How to rename a specific columns in a dataframe?\n",
    "Rename the column ***Type*** as ***CarType*** in df and replace the ‘.’ in column names with ‘_’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Manufacturer', 'Model', 'CarType', 'Min_Price', 'Price', 'Max_Price',\n",
      "       'MPG_city', 'MPG_highway', 'AirBags', 'DriveTrain', 'Cylinders',\n",
      "       'EngineSize', 'Horsepower', 'RPM', 'Rev_per_mile', 'Man_trans_avail',\n",
      "       'Fuel_tank_capacity', 'Passengers', 'Length', 'Wheelbase', 'Width',\n",
      "       'Turn_circle', 'Rear_seat_room', 'Luggage_room', 'Weight', 'Origin',\n",
      "       'Make'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "# Step 1:\n",
    "df=df.rename(columns = {'Type':'CarType'})\n",
    "# or\n",
    "df.columns.values[2] = \"CarType\"\n",
    "\n",
    "# Step 2:\n",
    "df.columns = df.columns.map(lambda x: x.replace('.', '_'))\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 40. How to check if a dataframe has any missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "df.isnull().values.any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 41. How to count the number of missing values in each column?\n",
    "Count the number of missing values in each column of ***df***. Which column has the maximum number of missing values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Luggage.room'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "n_missings_each_col = df.apply(lambda x: x.isnull().sum())\n",
    "n_missings_each_col.idxmax()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 43. How to use apply function on existing columns with global variables as additional arguments?\n",
    "In ***df***, use apply method to replace the missing values in ***Min.Price*** with the column’s mean and those in ***Max.Price*** with the column’s median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "d = {'Min.Price': np.nanmean, 'Max.Price': np.nanmedian}\n",
    "df[['Min.Price', 'Max.Price']] = df[['Min.Price', 'Max.Price']].apply(lambda x, d: x.fillna(d[x.name](x)), args=(d, ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a dictionary of the 26 english alphabets mapping each with the corresponding integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a': 1,\n",
       " 'b': 2,\n",
       " 'c': 3,\n",
       " 'd': 4,\n",
       " 'e': 5,\n",
       " 'f': 6,\n",
       " 'g': 7,\n",
       " 'h': 8,\n",
       " 'i': 9,\n",
       " 'j': 10,\n",
       " 'k': 11,\n",
       " 'l': 12,\n",
       " 'm': 13,\n",
       " 'n': 14,\n",
       " 'o': 15,\n",
       " 'p': 16,\n",
       " 'q': 17,\n",
       " 'r': 18,\n",
       " 's': 19,\n",
       " 't': 20,\n",
       " 'u': 21,\n",
       " 'v': 22,\n",
       " 'w': 23,\n",
       " 'x': 24,\n",
       " 'y': 25,\n",
       " 'z': 26}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution 1\n",
    "import string\n",
    "{a:i+1 for a,i in zip(string.ascii_letters[:26], range(26))}\n",
    "\n",
    "# Solution 2\n",
    "alphabets = 'abcdefghijklmnopqrstuvwxyz'\n",
    "{i: list(alphabets).index(i) + 1 for i in list(alphabets)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Replace all alphabets in the string ‘Lee Quan Yew’, by substituting the alphabet with the corresponding numbers, like 1 for ‘a’, 2 for ‘b’ and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[12, 5, 5, ' ', 17, 21, 1, 14, ' ', 25, 5, 23]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Solution\n",
    "import string\n",
    "d = {a:i+1 for a,i in zip(string.ascii_lowercase, range(26))}\n",
    "[d.get(a.lower(), ' ') for a in 'Lee Quan Yew']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the unique list of words from the following sentences, excluding any stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'face',\n",
       " 'formation',\n",
       " 'galaxies',\n",
       " 'has',\n",
       " 'hubble',\n",
       " 'resembles',\n",
       " 'sky',\n",
       " 'smiling',\n",
       " 'space',\n",
       " 'spotted',\n",
       " 'telescope',\n",
       " 'that'}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "sentences = [\"The Hubble Space telescope has spotted\", \n",
    "             \"a formation of galaxies that resembles\", \n",
    "             \"a smiling face in the sky\"]\n",
    "stopwords = ['for', 'a', 'of', 'the', 'and', 'to', 'in', 'on', 'with']\n",
    "\n",
    "# Solution\n",
    "{word.lower() for sentence in sentences for word in sentence.split(' ') if word.lower() not in stopwords}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize the following sentences excluding all stopwords and punctuations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['hubble', 'space', 'telescope', 'has', 'spotted'],\n",
       " ['formation', 'galaxies', 'that', 'resembles'],\n",
       " ['smiling', 'face', 'sky'],\n",
       " ['image', 'taken', 'wide', 'field', 'camera'],\n",
       " ['shows', 'patch', 'space', 'filled', 'galaxies'],\n",
       " ['all', 'shapes,', 'colours', 'sizes']]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "sentences = [\"The Hubble Space telescope has spotted\", \n",
    "             \"a formation of galaxies that resembles\", \n",
    "             \"a smiling face in the sky\", \n",
    "             \"The image taken with the Wide Field Camera\", \n",
    "             \"shows a patch of space filled with galaxies\", \n",
    "             \"of all shapes, colours and sizes\"]\n",
    "\n",
    "stopwords = ['for', 'a', 'of', 'the', 'and', 'to', 'in', 'on', 'with']\n",
    "\n",
    "# Solution\n",
    "[[word.lower() for word in sentence.split(' ') if word.lower() not in stopwords] for sentence in sentences]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a list of _(word:id)_ pairs for all words in the following sentences, where _id_ is the sentence index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 0),\n",
       " ('hubble', 0),\n",
       " ('space', 0),\n",
       " ('telescope', 0),\n",
       " ('has', 0),\n",
       " ('spotted', 0),\n",
       " ('a', 1),\n",
       " ('formation', 1),\n",
       " ('of', 1),\n",
       " ('galaxies', 1),\n",
       " ('that', 1),\n",
       " ('resembles', 1),\n",
       " ('a', 2),\n",
       " ('smiling', 2),\n",
       " ('face', 2),\n",
       " ('in', 2),\n",
       " ('the', 2),\n",
       " ('sky', 2)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "sentences = [\"The Hubble Space telescope has spotted\", \n",
    "             \"a formation of galaxies that resembles\", \n",
    "             \"a smiling face in the sky\"]\n",
    "\n",
    "# Solution\n",
    "[(word.lower(), i) for i, sentence in enumerate(sentences) for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 44. How to select a specific column from a dataframe as a dataframe instead of a series?\n",
    "Get the first column ***(a)*** in ***df*** as a dataframe (rather than as a Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "# Solution\n",
    "print(type(df[['a']]))\n",
    "type(df.loc[:, ['a']])\n",
    "type(df.iloc[:, [0]])\n",
    "\n",
    "# Alternately the following returns a Series\n",
    "type(df.a)\n",
    "type(df['a'])\n",
    "type(df.loc[:, 'a'])\n",
    "type(df.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 45. How to change the order of columns of a dataframe?\n",
    "Actually 3 questions.\n",
    "* In ***df***, interchange columns ***'a'*** and ***'c'***.\n",
    "* Create a generic function to interchange two columns, without hardcoding column names.\n",
    "* Sort the columns in reverse alphabetical order, that is colume ***'e'*** first through column ***'a'*** last."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.arange(20).reshape(-1, 5), columns=list('abcde'))\n",
    "\n",
    "# Solution Q1\n",
    "df[list('cbade')]\n",
    "\n",
    "# Solution Q2 - No hard coding\n",
    "def switch_columns(df, col1=None, col2=None):\n",
    "    colnames = df.columns.tolist()\n",
    "    i1, i2 = colnames.index(col1), colnames.index(col2)\n",
    "    colnames[i2], colnames[i1] = colnames[i1], colnames[i2]\n",
    "    return df[colnames]\n",
    "\n",
    "df1 = switch_columns(df, 'a', 'c')\n",
    "\n",
    "# Solution Q3\n",
    "df[sorted(df.columns)]\n",
    "# or\n",
    "df.sort_index(axis=1, ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 46. How to set the number of rows and columns displayed in the output?\n",
    "Change the pamdas display settings on printing the dataframe ***df*** it shows a maximum of 10 rows and 10 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Price</th>\n",
       "      <th>...</th>\n",
       "      <th>Rear.seat.room</th>\n",
       "      <th>Luggage.room</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Origin</th>\n",
       "      <th>Make</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>15.9</td>\n",
       "      <td>...</td>\n",
       "      <td>26.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2705.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Acura Integra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>33.9</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3560.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Acura Legend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>29.1</td>\n",
       "      <td>...</td>\n",
       "      <td>28.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>3375.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Audi 90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.7</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3405.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Audi 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3640.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>BMW 535i</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Eurovan</td>\n",
       "      <td>Van</td>\n",
       "      <td>16.6</td>\n",
       "      <td>19.7</td>\n",
       "      <td>...</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3960.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Volkswagen Eurovan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>Compact</td>\n",
       "      <td>17.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>31.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volkswagen Passat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Corrado</td>\n",
       "      <td>Sporty</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.3</td>\n",
       "      <td>...</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2810.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volkswagen Corrado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>240</td>\n",
       "      <td>Compact</td>\n",
       "      <td>21.8</td>\n",
       "      <td>22.7</td>\n",
       "      <td>...</td>\n",
       "      <td>29.5</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2985.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volvo 240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>NaN</td>\n",
       "      <td>850</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>24.8</td>\n",
       "      <td>26.7</td>\n",
       "      <td>...</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3245.0</td>\n",
       "      <td>non-USA</td>\n",
       "      <td>Volvo 850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Manufacturer    Model     Type  Min.Price  Price         ...          \\\n",
       "0         Acura  Integra    Small       12.9   15.9         ...           \n",
       "1           NaN   Legend  Midsize       29.2   33.9         ...           \n",
       "2          Audi       90  Compact       25.9   29.1         ...           \n",
       "3          Audi      100  Midsize        NaN   37.7         ...           \n",
       "4           BMW     535i  Midsize        NaN   30.0         ...           \n",
       "..          ...      ...      ...        ...    ...         ...           \n",
       "88   Volkswagen  Eurovan      Van       16.6   19.7         ...           \n",
       "89   Volkswagen   Passat  Compact       17.6   20.0         ...           \n",
       "90   Volkswagen  Corrado   Sporty       22.9   23.3         ...           \n",
       "91        Volvo      240  Compact       21.8   22.7         ...           \n",
       "92          NaN      850  Midsize       24.8   26.7         ...           \n",
       "\n",
       "    Rear.seat.room  Luggage.room  Weight   Origin                Make  \n",
       "0             26.5           NaN  2705.0  non-USA       Acura Integra  \n",
       "1             30.0          15.0  3560.0  non-USA        Acura Legend  \n",
       "2             28.0          14.0  3375.0  non-USA             Audi 90  \n",
       "3             31.0          17.0  3405.0  non-USA            Audi 100  \n",
       "4             27.0          13.0  3640.0  non-USA            BMW 535i  \n",
       "..             ...           ...     ...      ...                 ...  \n",
       "88            34.0           NaN  3960.0      NaN  Volkswagen Eurovan  \n",
       "89            31.5          14.0  2985.0  non-USA   Volkswagen Passat  \n",
       "90            26.0          15.0  2810.0  non-USA  Volkswagen Corrado  \n",
       "91            29.5          14.0  2985.0  non-USA           Volvo 240  \n",
       "92            30.0          15.0  3245.0  non-USA           Volvo 850  \n",
       "\n",
       "[93 rows x 27 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)\n",
    "df\n",
    "\n",
    "# Show all available options\n",
    "#pd.describe_option()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 47. How to format or suppress scientific notations in a pandas dataframe?\n",
    "Suppress scientific notations like ***‘e-03’*** in ***df*** and print upto 4 numbers after decimal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   random\n",
      "0  0.0002\n",
      "1  0.0066\n",
      "2  0.0000\n",
      "3  0.1072\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.random(4)**10, columns=['random'])\n",
    "\n",
    "# Solution 1: Rounding\n",
    "df.round(4)\n",
    "\n",
    "# Solution 2: Use apply to change format\n",
    "df.apply(lambda x: '%.4f' % x, axis=1)\n",
    "# or\n",
    "df.applymap(lambda x: '%.4f' % x)\n",
    "\n",
    "# Solution 3: Use set_option\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "# Solution 4: Assign display.float_format\n",
    "pd.options.display.float_format = '{:.4f}'.format\n",
    "print(df)\n",
    "\n",
    "# Reset/undo float formatting\n",
    "pd.options.display.float_format = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 48. How to format all the values in a dataframe as percentages?\n",
    "Format the values in column ***'random'*** of ***df*** as percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style>  \n",
       "<table id=\"T_fc8b8e06_f7d4_11e8_a156_107b447c783a\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >random</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_fc8b8e06_f7d4_11e8_a156_107b447c783alevel0_row0\" class=\"row_heading level0 row0\" >0</th> \n",
       "        <td id=\"T_fc8b8e06_f7d4_11e8_a156_107b447c783arow0_col0\" class=\"data row0 col0\" >57.76%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_fc8b8e06_f7d4_11e8_a156_107b447c783alevel0_row1\" class=\"row_heading level0 row1\" >1</th> \n",
       "        <td id=\"T_fc8b8e06_f7d4_11e8_a156_107b447c783arow1_col0\" class=\"data row1 col0\" >37.04%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_fc8b8e06_f7d4_11e8_a156_107b447c783alevel0_row2\" class=\"row_heading level0 row2\" >2</th> \n",
       "        <td id=\"T_fc8b8e06_f7d4_11e8_a156_107b447c783arow2_col0\" class=\"data row2 col0\" >67.65%</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_fc8b8e06_f7d4_11e8_a156_107b447c783alevel0_row3\" class=\"row_heading level0 row3\" >3</th> \n",
       "        <td id=\"T_fc8b8e06_f7d4_11e8_a156_107b447c783arow3_col0\" class=\"data row3 col0\" >23.46%</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x884b290>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.DataFrame(np.random.random(4), columns=['random'])\n",
    "\n",
    "# Solution\n",
    "out = df.style.format({\n",
    "    'random': '{0:.2%}'.format,\n",
    "})\n",
    "\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 49. How to filter every nth row in a dataframe?\n",
    "From ***df***, filter the ***'Manufacturer'***, ***'Model'*** and ***'Type'*** for every 20th row starting from 1st (row 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Manufacturer    Model     Type\n",
      "0         Acura  Integra    Small\n",
      "20     Chrysler  LeBaron  Compact\n",
      "40        Honda  Prelude   Sporty\n",
      "60      Mercury   Cougar  Midsize\n",
      "80       Subaru   Loyale    Small\n"
     ]
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv')\n",
    "\n",
    "# Solution\n",
    "print(df.iloc[::20, :][['Manufacturer', 'Model', 'Type']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 50. How to create a primary key index by combining relevant columns?\n",
    "In ***df***, Replace *NaNs* with *‘missing’* in columns ***'Manufacturer'***, ***'Model'*** and ***'Type'*** and create a index as a combination of these three columns and check if the index is a primary key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RangeIndex(start=0, stop=93, step=1)\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Manufacturer</th>\n",
       "      <th>Model</th>\n",
       "      <th>Type</th>\n",
       "      <th>Min.Price</th>\n",
       "      <th>Max.Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Acura_Integra_Small</th>\n",
       "      <td>Acura</td>\n",
       "      <td>Integra</td>\n",
       "      <td>Small</td>\n",
       "      <td>12.9</td>\n",
       "      <td>18.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_Legend_Midsize</th>\n",
       "      <td>missing</td>\n",
       "      <td>Legend</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>29.2</td>\n",
       "      <td>38.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi_90_Compact</th>\n",
       "      <td>Audi</td>\n",
       "      <td>90</td>\n",
       "      <td>Compact</td>\n",
       "      <td>25.9</td>\n",
       "      <td>32.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Audi_100_Midsize</th>\n",
       "      <td>Audi</td>\n",
       "      <td>100</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BMW_535i_Midsize</th>\n",
       "      <td>BMW</td>\n",
       "      <td>535i</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen_Eurovan_Van</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Eurovan</td>\n",
       "      <td>Van</td>\n",
       "      <td>16.6</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen_Passat_Compact</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>Compact</td>\n",
       "      <td>17.6</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volkswagen_Corrado_Sporty</th>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Corrado</td>\n",
       "      <td>Sporty</td>\n",
       "      <td>22.9</td>\n",
       "      <td>23.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volvo_240_Compact</th>\n",
       "      <td>Volvo</td>\n",
       "      <td>240</td>\n",
       "      <td>Compact</td>\n",
       "      <td>21.8</td>\n",
       "      <td>23.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing_850_Midsize</th>\n",
       "      <td>missing</td>\n",
       "      <td>850</td>\n",
       "      <td>Midsize</td>\n",
       "      <td>24.8</td>\n",
       "      <td>28.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Manufacturer    Model     Type  Min.Price  Max.Price\n",
       "Acura_Integra_Small              Acura  Integra    Small       12.9       18.8\n",
       "missing_Legend_Midsize         missing   Legend  Midsize       29.2       38.7\n",
       "Audi_90_Compact                   Audi       90  Compact       25.9       32.3\n",
       "Audi_100_Midsize                  Audi      100  Midsize        NaN       44.6\n",
       "BMW_535i_Midsize                   BMW     535i  Midsize        NaN        NaN\n",
       "...                                ...      ...      ...        ...        ...\n",
       "Volkswagen_Eurovan_Van      Volkswagen  Eurovan      Van       16.6       22.7\n",
       "Volkswagen_Passat_Compact   Volkswagen   Passat  Compact       17.6       22.4\n",
       "Volkswagen_Corrado_Sporty   Volkswagen  Corrado   Sporty       22.9       23.7\n",
       "Volvo_240_Compact                Volvo      240  Compact       21.8       23.5\n",
       "missing_850_Midsize            missing      850  Midsize       24.8       28.5\n",
       "\n",
       "[93 rows x 5 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/selva86/datasets/master/Cars93_miss.csv', usecols=[0,1,2,3,5])\n",
    "print(df.index)\n",
    "# Solution\n",
    "df[['Manufacturer', 'Model', 'Type']] = df[['Manufacturer', 'Model', 'Type']].fillna('missing')\n",
    "df.index = df.Manufacturer + '_' + df.Model + '_' + df.Type\n",
    "print(df.index.is_unique)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
